{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# BigP3BCI Demo\n",
    "This notebook demonstrates a P300 classification pipeline using the BigP3BCI dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "## Setup\n",
    "Load libraries and display versions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import mne\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from neurohub import (\n",
    "    load_raw,\n",
    "    bandpass,\n",
    "    decimate,\n",
    "    make_epochs,\n",
    "    extract_features,\n",
    "    lda_cv,\n",
    "    plot_erp,\n",
    ")\n",
    "\n",
    "print(\"MNE\", mne.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "## Data location\n",
    "Set the path to the dataset using the `NEURO_DATA_ROOT` environment variable (defaults to `~/neuro-data`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_env = os.environ.get(\"NEURO_DATA_ROOT\")\n",
    "if root_env:\n",
    "    data_root = Path(root_env).expanduser()\n",
    "else:\n",
    "    repo_base = Path.cwd().parent / \"data\"\n",
    "    data_root = (\n",
    "        repo_base\n",
    "        / \"bigp3bci-an-open-diverse-and-machine-learning-ready-p300-based-brain-computer-interface-dataset-1.0.0\"\n",
    "    )\n",
    "subject_dir = data_root / \"bigP3BCI-data\" / \"StudyA\" / \"A_01\" / \"SE001\"\n",
    "train_path = subject_dir / \"Train\" / \"CB\" / \"A_01_SE001_CB_Train01.edf\"\n",
    "test_path = subject_dir / \"Test\" / \"CB\" / \"A_01_SE001_CB_Test06.edf\"\n",
    "print(\"Train file\", train_path)\n",
    "print(\"Test file\", test_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "## Load raw EEG\n",
    "We read one calibration run and one test run from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_train = load_raw(train_path)\n",
    "raw_test = load_raw(test_path)\n",
    "print(raw_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "## Extract stimulus events\n",
    "Events are stored in the `StimulusBegin` channel. The `StimulusType` channel encodes whether the flash contained the target (1) or not (0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def annotate_events(raw):\n",
    "    stim_begin = raw.get_data(picks=[\"StimulusBegin\"])[0]\n",
    "    stim_type = raw.get_data(picks=[\"StimulusType\"])[0].astype(int)\n",
    "    onsets = np.where(stim_begin > 0)[0] / raw.info[\"sfreq\"]\n",
    "    desc = np.where(stim_type[stim_begin > 0] > 0, \"target\", \"non\")\n",
    "    raw.set_annotations(mne.Annotations(onsets, [0] * len(onsets), desc))\n",
    "    drop = [\n",
    "        \"StimulusBegin\",\n",
    "        \"StimulusType\",\n",
    "        \"StimulusCode\",\n",
    "        \"CurrentTarget\",\n",
    "        \"FakeFeedback\",\n",
    "        \"DisplayResults\",\n",
    "        \"SelectedTarget\",\n",
    "        \"SelectedRow\",\n",
    "        \"SelectedColumn\",\n",
    "        \"PhaseInSequence\",\n",
    "    ]\n",
    "    raw.drop_channels([ch for ch in drop if ch in raw.ch_names])\n",
    "    return desc\n",
    "\n",
    "\n",
    "train_desc = annotate_events(raw_train)\n",
    "test_desc = annotate_events(raw_test)\n",
    "print(\"Train events\", np.unique(train_desc, return_counts=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "We band-pass filter from 0.1–30 Hz and resample to 128 Hz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "bandpass(raw_train)\n",
    "bandpass(raw_test)\n",
    "decimate(raw_train)\n",
    "decimate(raw_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "## Epoch extraction\n",
    "We epoch from −0.2…0.8 s relative to each stimulus and apply baseline correction using the pre-stimulus period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmin, tmax = -0.2, 0.8\n",
    "train_epochs = make_epochs(raw_train, tmin, tmax)\n",
    "test_epochs = make_epochs(raw_test, tmin, tmax)\n",
    "train_epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "## ERP grand average\n",
    "Plot the average waveform for target and non-target trials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_erp(train_epochs)\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "## Feature extraction and classification\n",
    "We vectorize the 250–450 ms window and train an LDA on calibration data, then evaluate on the test run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = extract_features(train_epochs)\n",
    "X_test, y_test = extract_features(test_epochs)\n",
    "cv_acc = lda_cv(X_train, y_train)\n",
    "clf = LinearDiscriminantAnalysis().fit(X_train, y_train)\n",
    "score = clf.score(X_test, y_test)\n",
    "print(f\"CV accuracy: {cv_acc:.3f}, Test accuracy: {score:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "## Confusion matrix\n",
    "Examine classifier performance on the test run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "fig, ax = plt.subplots()\n",
    "im = ax.imshow(cm, cmap=\"Blues\")\n",
    "ax.set_xlabel(\"Predicted\")\n",
    "ax.set_ylabel(\"True\")\n",
    "ax.set_xticks([0, 1])\n",
    "ax.set_xticklabels([\"Non-target\", \"Target\"])\n",
    "ax.set_yticks([0, 1])\n",
    "ax.set_yticklabels([\"Non-target\", \"Target\"])\n",
    "for (i, j), v in np.ndenumerate(cm):\n",
    "    ax.text(j, i, str(v), ha=\"center\", va=\"center\")\n",
    "fig.colorbar(im, ax=ax)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}