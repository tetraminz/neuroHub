{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# BigP3BCI Demo\n",
    "This notebook demonstrates a P300 classification pipeline using the BigP3BCI dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "## Setup\n",
    "Load libraries and display versions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import mne\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"MNE\", mne.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "## Data location\n",
    "Set the path to the dataset using the `NEURO_DATA_ROOT` environment variable (defaults to `~/neuro-data`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root = Path(os.environ.get(\"NEURO_DATA_ROOT\", \"\"))\n",
    "if not data_root.exists():\n",
    "    repo_base = Path.cwd() / \"data\"\n",
    "    data_root = (\n",
    "        repo_base\n",
    "        / \"bigp3bci-an-open-diverse-and-machine-learning-ready-p300-based-brain-computer-interface-dataset-1.0.0\"\n",
    "    )\n",
    "subject_dir = data_root / \"bigP3BCI-data\" / \"StudyA\" / \"A_01\" / \"SE001\"\n",
    "train_path = subject_dir / \"Train\" / \"CB\" / \"A_01_SE001_CB_Train01.edf\"\n",
    "test_path = subject_dir / \"Test\" / \"CB\" / \"A_01_SE001_CB_Test06.edf\"\n",
    "print(\"Train file\", train_path)\n",
    "print(\"Test file\", test_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "## Load raw EEG\n",
    "We read one calibration run and one test run from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_train = mne.io.read_raw_edf(train_path, preload=True, verbose=False)\n",
    "raw_test = mne.io.read_raw_edf(test_path, preload=True, verbose=False)\n",
    "print(raw_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "## Extract stimulus events\n",
    "Events are stored in the `StimulusBegin` channel. The `StimulusType` channel encodes whether the flash contained the target (1) or not (0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_events(raw):\n",
    "    stim_begin = raw.get_data(picks=[\"StimulusBegin\"])[0]\n",
    "    stim_type = raw.get_data(picks=[\"StimulusType\"])[0]\n",
    "    onsets = np.where(stim_begin > 0)[0]\n",
    "    events = np.c_[onsets, np.zeros(len(onsets), int), stim_type[onsets].astype(int)]\n",
    "    return events\n",
    "\n",
    "\n",
    "train_events = extract_events(raw_train)\n",
    "test_events = extract_events(raw_test)\n",
    "print(\"Train events\", np.unique(train_events[:, 2], return_counts=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "We band-pass filter from 0.1–30 Hz and resample to 128 Hz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_train.filter(0.1, 30.0, fir_design=\"firwin\", verbose=False)\n",
    "raw_test.filter(0.1, 30.0, fir_design=\"firwin\", verbose=False)\n",
    "raw_train.resample(128, verbose=False)\n",
    "raw_test.resample(128, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "## Epoch extraction\n",
    "We epoch from −0.2…0.8 s relative to each stimulus and apply baseline correction using the pre-stimulus period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmin, tmax = -0.2, 0.8\n",
    "event_id = dict(nontarget=0, target=1)\n",
    "train_epochs = mne.Epochs(\n",
    "    raw_train,\n",
    "    train_events,\n",
    "    event_id=event_id,\n",
    "    tmin=tmin,\n",
    "    tmax=tmax,\n",
    "    baseline=(tmin, 0),\n",
    "    preload=True,\n",
    "    verbose=False,\n",
    ")\n",
    "test_epochs = mne.Epochs(\n",
    "    raw_test,\n",
    "    test_events,\n",
    "    event_id=event_id,\n",
    "    tmin=tmin,\n",
    "    tmax=tmax,\n",
    "    baseline=(tmin, 0),\n",
    "    preload=True,\n",
    "    verbose=False,\n",
    ")\n",
    "train_epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "## ERP grand average\n",
    "Plot the average waveform for target and non-target trials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_epochs[\"target\"].average().plot(spatial_colors=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "## Feature extraction and classification\n",
    "We vectorize the 250–450 ms window and train an LDA on calibration data, then evaluate on the test run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "window = train_epochs.time_as_index([0.25, 0.45])\n",
    "X_train = train_epochs.get_data()[:, :, window[0] : window[1]].reshape(\n",
    "    len(train_epochs), -1\n",
    ")\n",
    "y_train = train_epochs.events[:, 2]\n",
    "X_test = test_epochs.get_data()[:, :, window[0] : window[1]].reshape(\n",
    "    len(test_epochs), -1\n",
    ")\n",
    "y_test = test_epochs.events[:, 2]\n",
    "clf = LinearDiscriminantAnalysis()\n",
    "clf.fit(X_train, y_train)\n",
    "score = clf.score(X_test, y_test)\n",
    "print(f\"Test accuracy: {score:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "## Confusion matrix\n",
    "Examine classifier performance on the test run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "fig, ax = plt.subplots()\n",
    "im = ax.imshow(cm, cmap=\"Blues\")\n",
    "ax.set_xlabel(\"Predicted\")\n",
    "ax.set_ylabel(\"True\")\n",
    "ax.set_xticks([0, 1])\n",
    "ax.set_xticklabels([\"Non-target\", \"Target\"])\n",
    "ax.set_yticks([0, 1])\n",
    "ax.set_yticklabels([\"Non-target\", \"Target\"])\n",
    "for (i, j), v in np.ndenumerate(cm):\n",
    "    ax.text(j, i, str(v), ha=\"center\", va=\"center\")\n",
    "fig.colorbar(im, ax=ax)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
